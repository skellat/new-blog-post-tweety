Well, teaching got weird Tuesday night. I ended up having to react to
Google announcing during its conference session that day that they were
migrating their Search product toward being an experience built of
Genrative Artificial Intelligence. While it may seem like that might be
a sufficiently innocuous thing to do with Generative Artificial
Intelligence it should be considered that problems can be found below
the surface.

In this particular case, Google has made the awesome business decision
to
\href{https://web.archive.org/web/20240515053544/https://blog.google/products/search/generative-ai-google-search-may-2024/}{take
its Generative AI product known as Gemini and make it the front end to
search}. It is a bold bet. For as inaccurate as Gemini winds up being,
this could definitely damage democrarcy. Generative Artificial
Intelligence has accuracy problems and definitely will \emph{lie} to its
users. Now we're going to entrust search to a digital construct that is
about as accurate as a drunken know-it-all friend that has a blood
alcohol content measure of 1.99.

As I wound up going through exercises with my students, they wound up
seeing ways that Gemini is so very wrong. As noted by Taxpayer Advocate
Service and the Treasury Inspector General for Tax Administration,
utilizing any sort of Generative Artificial Intelligence system for tax
advice generally results in not just wrong answers but very wrong
answers that can lead to massive penalties. I showed them a massive one
and how to actually get to \emph{correct} information about what tax law
actually says that is actually readable.

They were initially confused when I asked them if they knew how to find
the sites of one or more news outlets. If this AI front-end to search is
just going to summarize everything and not give you links to what you're
actually seeing then are you actually getting the news? Are you getting
something that is just confirming your biases instead? Are you getting
something that will lie to you and tell you that nothing is going on
even when there actually \emph{is} something going on? People generally
just click on the first link or two that they get from Google. If they
get no links and instead just get some made up crap from a program that
is known to lie they are quite likely going to take it as gospel truth.

I initially wanted to title this ``Google Search Deemed Harmful'' but
that style title is old and busted. Frankly I don't know what to do with
things now. Google is simply becoming an increasing danger to having any
sort of a functional society. It counterparts among the GAFAM and FAANG
groups are not helping with that either.

I'm not necessarily saying we took a wrong turn moving away from the
time of the BBS. I am saying that shifting back to that might not be
such a bad idea for having somewhat untainted information systems. As
the Internet continues to be polluted with AI-generated crap we might
end up in an endgame such as those postulated by Michael Z. Williamson
and Mike Pondsmith where the Internet becomes a totally unusable mess
that can't be fixed.
